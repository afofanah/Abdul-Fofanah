{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make the imports of python packages needed\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "#Import the dataset and define the feature as well as the target datasets / columns#\n",
    "dataset = pd.read_csv('zoo.csv',\n",
    "                      names=['animal_name','hair','feathers','eggs','milk',\n",
    "                                                   'airbone','aquatic','predator','toothed','backbone',\n",
    "                                                  'breathes','venomous','fins','legs','tail','domestic','catsize','class',])\n",
    "#Import all columns omitting the fist which consists the names of the animals\n",
    "#We drop the animal names since this is not a good feature to split the data on\n",
    "dataset=dataset.drop('animal_name',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hair</th>\n",
       "      <th>feathers</th>\n",
       "      <th>eggs</th>\n",
       "      <th>milk</th>\n",
       "      <th>airbone</th>\n",
       "      <th>aquatic</th>\n",
       "      <th>predator</th>\n",
       "      <th>toothed</th>\n",
       "      <th>backbone</th>\n",
       "      <th>breathes</th>\n",
       "      <th>venomous</th>\n",
       "      <th>fins</th>\n",
       "      <th>legs</th>\n",
       "      <th>tail</th>\n",
       "      <th>domestic</th>\n",
       "      <th>catsize</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hair  feathers  eggs  milk  airbone  aquatic  predator  toothed  backbone  \\\n",
       "0     1         0     0     1        0        0         1        1         1   \n",
       "1     1         0     0     1        0        0         0        1         1   \n",
       "2     0         0     1     0        0        1         1        1         1   \n",
       "3     1         0     0     1        0        0         1        1         1   \n",
       "4     1         0     0     1        0        0         1        1         1   \n",
       "\n",
       "   breathes  venomous  fins  legs  tail  domestic  catsize  class  \n",
       "0         1         0     0     4     0         0        1      1  \n",
       "1         1         0     0     4     1         0        1      1  \n",
       "2         0         0     1     0     1         0        0      4  \n",
       "3         1         0     0     4     0         0        1      1  \n",
       "4         1         0     0     4     1         0        1      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target_col):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a dataset.\n",
    "    The only parameter of this function is the target_col parameter which specifies the target column\n",
    "    \"\"\"\n",
    "    elements,counts = np.unique(target_col,return_counts = True)\n",
    "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InfoGain(data,split_attribute_name,target_name=\"class\"):\n",
    "    \"\"\"\n",
    "    Calculate the information gain of a dataset. This function takes three parameters:\n",
    "    1. data = The dataset for whose feature the IG should be calculated\n",
    "    2. split_attribute_name = the name of the feature for which the information gain should be calculated\n",
    "    3. target_name = the name of the target feature. The default for this example is \"class\"\n",
    "    \"\"\"    \n",
    "    #Calculate the entropy of the total dataset\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    \n",
    "    ##Calculate the entropy of the dataset\n",
    "    \n",
    "    #Calculate the values and the corresponding counts for the split attribute \n",
    "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
    "    \n",
    "    #Calculate the weighted entropy\n",
    "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()\n",
    "                                                                  [target_name]) for i in range(len(vals))])\n",
    "    \n",
    "    #Calculate the information gain\n",
    "    Information_Gain = total_entropy - Weighted_Entropy\n",
    "    return Information_Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(data,originaldata,features,target_attribute_name=\"class\",parent_node_class = None):\n",
    "    \"\"\"\n",
    "    ID3 Algorithm: This function takes five paramters:\n",
    "    1. data = the data for which the ID3 algorithm should be run --> In the first run this equals the total dataset\n",
    " \n",
    "    2. originaldata = This is the original dataset needed to calculate the mode target feature value of the original dataset\n",
    "    in the case the dataset delivered by the first parameter is empty\n",
    "    3. features = the feature space of the dataset . This is needed for the recursive call since during the tree growing process\n",
    "    we have to remove features from our dataset --> Splitting at each node\n",
    "    4. target_attribute_name = the name of the target attribute\n",
    "    5. parent_node_class = This is the value or class of the mode target feature value of the parent node for a specific node. This is \n",
    "    also needed for the recursive call since if the splitting leads to a situation that there are no more features left in the feature\n",
    "    space, we want to return the mode target feature value of the direct parent node.\n",
    "    \"\"\"   \n",
    "    #Define the stopping criteria --> If one of this is satisfied, we want to return a leaf node#\n",
    "    \n",
    "    #If all target_values have the same value, return this value\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    \n",
    "    #If the dataset is empty, return the mode target feature value in the original dataset\n",
    "    elif len(data)==0:\n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
    "    \n",
    "    #If the feature space is empty, return the mode target feature value of the direct parent node --> Note that\n",
    "    #the direct parent node is that node which has called the current run of the ID3 algorithm and hence\n",
    "    #the mode target feature value is stored in the parent_node_class variable.\n",
    "    \n",
    "    elif len(features) ==0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    #If none of the above holds true, grow the tree!\n",
    "    \n",
    "    else:\n",
    "        #Set the default value for this node --> The mode target feature value of the current node\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
    "        \n",
    "        #Select the feature which best splits the dataset\n",
    "        item_values = [InfoGain(data,feature,target_attribute_name) for feature in features] #Return the information gain values for the features in the dataset\n",
    "        best_feature_index = np.argmax(item_values)\n",
    "        best_feature = features[best_feature_index]\n",
    "        \n",
    "        #Create the tree structure. The root gets the name of the feature (best_feature) with the maximum information\n",
    "        #gain in the first run\n",
    "        tree = {best_feature:{}}\n",
    "        \n",
    "        \n",
    "        #Remove the feature with the best inforamtion gain from the feature space\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        #Grow a branch under the root node for each possible value of the root node feature\n",
    "        \n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            #Split the dataset along the value of the feature with the largest information gain and therewith create sub_datasets\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            \n",
    "            #Call the ID3 algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\n",
    "            subtree = ID3(sub_data,dataset,features,target_attribute_name,parent_node_class)\n",
    "            \n",
    "            #Add the sub tree, grown from the sub_dataset to the tree under the root node\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return(tree)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query,tree,default = 1):\n",
    "    \"\"\"\n",
    "    Prediction of a new/unseen query instance. This takes two parameters:\n",
    "    \n",
    "    SUMMARIZED: If we have a query instance consisting of values for features, we take this features and check if the \n",
    "    name of the root node is equal to one of the query features.\n",
    "    If this is true, we run down the root node outgoing branch whose value equals the value of query feature == the root node.\n",
    "    If we find at the end of this branch a leaf node (not a dict object) we return this value (this is our prediction).\n",
    "    If we instead find another node (== sub_tree == dict objct) we search in our query for the feature which equals the value \n",
    "    of that node. Next we look up the value of our query feature and run down the branch whose value is equal to the \n",
    "    query[key] == query feature value. And as you can see this is exactly the recursion we talked about\n",
    "    with the important fact that for each node we run down the tree, we check only the nodes and branches which are \n",
    "    below this node and do not run the whole tree beginning at the root node \n",
    "    --> This is why we re-call the classification function with 'result'\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #1.\n",
    "    for key in list(query.keys()):\n",
    "        if key in list(tree.keys()):\n",
    "            #2.\n",
    "            try:\n",
    "                result = tree[key][query[key]] \n",
    "            except:\n",
    "                return default\n",
    "  \n",
    "            #3.\n",
    "            result = tree[key][query[key]]\n",
    "            #4.\n",
    "            if isinstance(result,dict):\n",
    "                return predict(query,result)\n",
    "            else:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset):\n",
    "    training_data = dataset.iloc[:80].reset_index(drop=True)#We drop the index respectively relabel the index\n",
    "    #starting form 0, because we do not want to run into errors regarding the row labels / indexes\n",
    "    testing_data = dataset.iloc[80:].reset_index(drop=True)\n",
    "    return training_data,testing_data\n",
    "training_data = train_test_split(dataset)[0]\n",
    "testing_data = train_test_split(dataset)[1] \n",
    "def test(data,tree):\n",
    "    #Create new query instances by simply removing the target feature column from the original dataset and \n",
    "    #convert it to a dictionary\n",
    "    queries = data.iloc[:,:-1].to_dict(orient = \"records\")\n",
    "    #Create a empty DataFrame in whose columns the prediction of the tree are stored\n",
    "    predicted = pd.DataFrame(columns=[\"predicted\"]) \n",
    "    \n",
    "    #Calculate the prediction accuracy\n",
    "    for i in range(len(data)):\n",
    "        predicted.loc[i,\"predicted\"] = predict(queries[i],tree,1.0) \n",
    "    print('The prediction accuracy is: ',(np.sum(predicted[\"predicted\"] == data[\"class\"])/len(data))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'legs': {0: {'fins': {0.0: {'toothed': {0.0: 7.0, 1.0: 3.0}},\n",
      "                       1.0: {'eggs': {0.0: 1.0, 1.0: 4.0}}}},\n",
      "          2: {'hair': {0.0: 2.0, 1.0: 1.0}},\n",
      "          4: {'hair': {0.0: {'toothed': {0.0: 7.0, 1.0: 5.0}}, 1.0: 1.0}},\n",
      "          6: {'aquatic': {0.0: 6.0, 1.0: 7.0}},\n",
      "          8: 7.0}}\n",
      "The prediction accuracy is:  85.71428571428571 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train the tree, Print the tree and predict the accuracy\n",
    "\"\"\"\n",
    "tree = ID3(training_data,training_data,training_data.columns[:-1])\n",
    "pprint(tree)\n",
    "test(testing_data,tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.randint(low=1, high=11, size=50)\n",
    "y = x + np.random.randint(1, 5, size=x.size)\n",
    "data = np.column_stack((x, y))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2,\n",
    "                              figsize=(8, 4))\n",
    "\n",
    "ax1.scatter(x=x, y=y, marker='o', c='r', edgecolor='b')\n",
    "ax1.set_title('Scatter: $x$ versus $y$')\n",
    "ax1.set_xlabel('$x$')\n",
    "ax1.set_ylabel('$y$')\n",
    "\n",
    "ax2.hist(data, bins=np.arange(data.min(), data.max()),\n",
    "       label=('x', 'y'))\n",
    "ax2.legend(loc=(0.65, 0.8))\n",
    "ax2.set_title('Frequencies of $x$ and $y$')\n",
    "ax2.yaxis.tick_right()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
